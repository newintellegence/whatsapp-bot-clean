
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.text_splitter import CharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI
from langchain.docstore.document import Document
import os
from dotenv import load_dotenv

# ุชุญููู ูุชุบูุฑุงุช ุงูุจูุฆุฉ
load_dotenv()

# ูุญุชูู ุงูุฎุฏูุฉ ููุต ุนุงุฏู
knowledge_text = """
ุฃูุง ุนุจุฏุงูุฑุญููุ ููุฏู ุฎุฏูุฉ New Intelligence ุงููุชุฎุตุตุฉ ูู ุชุตููู ุดุงุช ุจูุชุงุช ูุงุชุณุงุจ ุฐููุฉ ููุฃุนูุงู.
ุฃุณุงุนุฏ ุงูุนูุงุฏุงุชุ ุงููุชุงุฌุฑุ ูุงูุฌูุนูุงุช ูู ุฃุชูุชุฉ ุงูุชูุงุตู ูุน ุงูุนููุงุก ุจุงูููุฌุฉ ุงูุณุนูุฏูุฉ.

๐น ูุง ููุฏูู:
- ุฅูุดุงุก ุจูุช ูุงุชุณุงุจ ูุฎุตุต ุจุงุณุชุฎุฏุงู Python + Flask
- ุชูุงูู ูุน ChatGPT (OpenAI API) ูุชูุฏูู ุฑุฏูุฏ ุฐููุฉ
- ุฑุจุท ูุน Twilio ูุงุณุชูุจุงู ุงูุฑุณุงุฆู ูุงูุฑุฏ ุชููุงุฆูุงู
- ูุดุฑ ุงูุจูุช ุนูู ุงูุฅูุชุฑูุช ุจุงุณุชุฎุฏุงู Render ุฃู n8n
- ุชุฎุตูุต ูุบูุฉ ุงูุจูุช ูุชููู ุงุญุชุฑุงููุฉ ูุจุงูููุฌุฉ ุงูุณุนูุฏูุฉ

๐น ุงูุฎุทุท ูุงูุฃุณุนุงุฑ:
1. ุฅุนุฏุงุฏ ุจูุช ุจุณูุท ุจุงุณุชุฎุฏุงู n8n โ ูู 150 ุฅูู 300 ุฑูุงู
2. ุฅุนุฏุงุฏ ุจูุช ุฐูู ุจู Python โ ูู 400 ุฅูู 1500 ุฑูุงู
3. ุฏุนู ุดูุฑู (ุชุญุฏูุซุงุช + ุตูุงูุฉ + ูุฑุงูุจุฉ) โ ูู 50 ุฅูู 400 ุฑูุงู

๐น ูููุฒุงุช ุงูุจูุช:
- ูุชููู ุจููุฌุฉ ุณุนูุฏูุฉ ูุจูุฉ (ูุซู: ุญูุงูุ ููุง ูุงูููุ ุงุจุดุฑ)
- ูุฑุฏ ุจุณุฑุนุฉ ูุงุญุชุฑุงููุฉ ุนูู ุงุณุชูุณุงุฑุงุช ุงูุนููุงุก
- ููุชุฑุญ ุญููู ููููุฐ ุฃูุงูุฑ ุชููุงุฆูุฉ
- ูุงุจู ููุชุทููุฑ ูุงูุฑุจุท ูุน ููุงุนุฏ ูุนุฑูุฉ ูุฎุตุตุฉ

๐ ููุชูุงุตู:
ุฑูู ุงูุฌูุงู: 0568604393
ุงูุจุฑูุฏ ุงูุฅููุชุฑููู: newstats25@gmail.com
"""

# ุชุฌุฒุฆุฉ ุงููุต ุฅูู ููุงุทุน ุตุบูุฑุฉ
text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
docs = text_splitter.split_documents([Document(page_content=knowledge_text)])

# ุจูุงุก ูุงุนุฏุฉ ุงููุนุฑูุฉ ุจุงุณุชุฎุฏุงู FAISS
embedding = OpenAIEmbeddings(openai_api_key=os.getenv("OPENAI_API_KEY"))
vectorstore = FAISS.from_documents(docs, embedding)

# ุฅุนุฏุงุฏ ูููุฐุฌ ุงูุฃุณุฆูุฉ ูุงูุฅุฌุงุจุงุช
qa = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(openai_api_key=os.getenv("OPENAI_API_KEY"), temperature=0),
    chain_type="stuff",
    retriever=vectorstore.as_retriever()
)

# ุชุฌุฑุจุฉ ุณุคุงู
question = input("ุงุณุฃู ุนู ุงูุฎุฏูุฉ: ")
answer = qa.run(question)
print("\nุงูุฑุฏ ูู ูุงุนุฏุฉ ุงููุนุฑูุฉ:")
print(answer)
